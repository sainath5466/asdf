{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainath5466/asdf/blob/main/notebooks/catboost%20regression%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q6q194jpSPXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b440834f-6c8c-41d5-b47e-87e9eef86480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq yellowbrick category_encoders catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some builtin imports\n",
        "import re\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import time\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Some usual imports here\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "\n",
        "# sklearn models\n",
        "from sklearn import metrics, model_selection\n",
        "\n",
        "import catboost as cb\n",
        "\n",
        "# visualizations\n",
        "import shap\n",
        "from yellowbrick.regressor import residuals_plot, prediction_error"
      ],
      "metadata": {
        "id": "2yWBGgT2SbE_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Customize Matplotlib Parameters\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.dpi']= 120\n",
        "mpl.rcParams['figure.edgecolor']= 'black'\n",
        "mpl.rcParams['axes.linewidth']= .5\n",
        "# Customize Seaborn Parameters\n",
        "sns.set()\n",
        "rc = {\n",
        "      'font.family': ['serif'],\n",
        "      'font.serif':'Times New Roman',\n",
        "      'grid.color': 'gainsboro',\n",
        "      'grid.linestyle': '-',\n",
        "}\n",
        "sns.set_style(rc=rc)\n",
        "sns.set_context(\"notebook\", font_scale=0.8)"
      ],
      "metadata": {
        "id": "-dD4lh6SS8hZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "3iEbuW8ATEyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('house_rentals.csv')"
      ],
      "metadata": {
        "id": "KZAw3fTCTDJC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5oX7LubTNii",
        "outputId": "29bb8b52-b7da-4013-ed2b-9e0f1ae4e089"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17890 entries, 0 to 17889\n",
            "Data columns (total 17 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   url            17890 non-null  object \n",
            " 1   listing_type   17890 non-null  object \n",
            " 2   name           17890 non-null  object \n",
            " 3   price          17890 non-null  int64  \n",
            " 4   category       17890 non-null  object \n",
            " 5   bedrooms       17890 non-null  float64\n",
            " 6   bathrooms      17890 non-null  float64\n",
            " 7   floor_area     17890 non-null  float64\n",
            " 8   location       17890 non-null  object \n",
            " 9   condition      17890 non-null  object \n",
            " 10  amenities      17890 non-null  object \n",
            " 11  region         17890 non-null  object \n",
            " 12  locality       17890 non-null  object \n",
            " 13  parking_space  17890 non-null  bool   \n",
            " 14  is_furnished   17890 non-null  object \n",
            " 15  lat            17890 non-null  float64\n",
            " 16  lng            17890 non-null  float64\n",
            "dtypes: bool(1), float64(5), int64(1), object(10)\n",
            "memory usage: 2.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CatBoost Regressor"
      ],
      "metadata": {
        "id": "4J-OT8xNTvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(model, x, y, cv=5):\n",
        "    preds = model.predict(x)\n",
        "    score = model.score(x, y)\n",
        "\n",
        "    scores_cvs = model_selection.cross_val_score(model, x, y, scoring='r2', cv=cv)\n",
        "\n",
        "    return pd.DataFrame([{\n",
        "        \"R2\": round(score, 3),\n",
        "        \"mse\": round(metrics.mean_squared_error(y, preds), 3),\n",
        "        \"rmse\": round(np.sqrt(metrics.mean_squared_error(y, preds)), 3),\n",
        "        \"mae\": round(metrics.mean_absolute_error(y, preds), 3),\n",
        "        \"adjusted_r2\": round(1 - (1 - score) * (len(y) - 1) / (len(y) - x.shape[1] - 1), 3),\n",
        "        \"cv_score\": round(scores_cvs.mean()*100, 2)\n",
        "    }])"
      ],
      "metadata": {
        "id": "SLGdb9UbUjgk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for model evaluation\n",
        "X = df.drop(['price'], axis=1).values # Remove 'log1p_price' from the list of columns to drop\n",
        "y = df['price'].values # Change the target variable from 'log1p_price' to 'price'\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, y, train_size=0.8, shuffle=True, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "UQo23nH6TPco"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk1jutoMUFo3",
        "outputId": "d8063eee-934f-4911-b26c-9f8e6778e9a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14312, 16), (3578, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for model evaluation\n",
        "X = df.drop(['price'], axis=1) # Keep DataFrame structure\n",
        "y = df['price'].values # Change the target variable from 'log1p_price' to 'price'\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, y, train_size=0.8, shuffle=True, random_state=42\n",
        ")\n",
        "\n",
        "# Replace 'url' and 'other_categorical_columns' with your actual categorical column names\n",
        "# Assuming 'url', 'category', 'condition' are your categorical columns, remove 'furnishing' if it's not present\n",
        "categorical_features_indices = [X_train.columns.get_loc(col) for col in ['url', 'category', 'condition']]\n",
        "\n",
        "# Before fitting the model, encode the categorical features using OrdinalEncoder:\n",
        "# Make sure 'furnishing' is removed from the list of columns if it's not in your DataFrame\n",
        "# Assuming 'url', 'category', 'condition' are your categorical features\n",
        "!pip install -qq category_encoders\n",
        "import category_encoders as ce\n",
        "encoder = ce.OrdinalEncoder(cols=['url', 'category', 'condition'])\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "# Now use the encoded data for training:\n",
        "model = cb.CatBoostRegressor(random_seed=42, logging_level='Silent')\n",
        "\n",
        "# Get the indices of the encoded categorical features in X_train_encoded\n",
        "encoded_categorical_features_indices = [X_train_encoded.columns.get_loc(col) for col in ['url', 'category', 'condition']]\n",
        "\n",
        "#Train with encoded data and encoded indices\n",
        "model = model.fit(X_train_encoded, y_train, cat_features=encoded_categorical_features_indices) # Pass encoded data and correct indices"
      ],
      "metadata": {
        "id": "7JlbqUHSUH9Y",
        "outputId": "908f7788-d767-4383-e2d7-3314f52a8b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=1]=\"rentals\": Cannot convert 'b'rentals'' to float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'rentals'' to float",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e17f5f3ebdcb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#Train with encoded data and encoded indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_categorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass encoded data and correct indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'loss_function'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5872\u001b[0m             \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5873\u001b[0;31m         return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n\u001b[0m\u001b[1;32m   5874\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5875\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m             train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2396\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m                 \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2273\u001b[0m         \u001b[0membedding_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2275\u001b[0;31m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs, graph,\n\u001b[0m\u001b[1;32m   2276\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m                                        baseline, column_description)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, graph=graph, weight=sample_weight, group_id=group_id,\n\u001b[0m\u001b[1;32m   1514\u001b[0m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[1;32m    853\u001b[0m                         )\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n\u001b[0m\u001b[1;32m    856\u001b[0m                                group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    857\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata_can_be_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_tags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0mfeature_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_transform_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight,\n\u001b[0m\u001b[1;32m   1492\u001b[0m                         group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=1]=\"rentals\": Cannot convert 'b'rentals'' to float"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training metrics\n"
      ],
      "metadata": {
        "id": "ESoCgUrTWqFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_metrics = compute_metrics(model, X_train, y_train)\n",
        "train_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "GYns5IqhWha7",
        "outputId": "ecea854e-81ab-411c-f9b9-419d33c55888"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-37c0abd0f62f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7bb2ae0bdb4d>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(model, x, y, cv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscores_cvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5923\u001b[0m             \u001b[0mprediction_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5924\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RawFormulaVal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2619\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2620\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_predict_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_method_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2594\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_predict_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_method_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_count_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2596\u001b[0;31m             raise CatBoostError((\"There is no trained model to use {}(). \"\n\u001b[0m\u001b[1;32m   2597\u001b[0m                                  \"Use fit() to train model. Then use this method.\").format(parent_method_name))\n\u001b[1;32m   2598\u001b[0m         \u001b[0mis_single_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_data_single_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation metrics\n"
      ],
      "metadata": {
        "id": "OzDyftLwWt5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics = compute_metrics(model, X_test, y_test)\n",
        "val_metrics"
      ],
      "metadata": {
        "id": "Me5FnJZEUXzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridSearch"
      ],
      "metadata": {
        "id": "ouYMWOnKrIEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_all_params()"
      ],
      "metadata": {
        "id": "SmojlvUu4tzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "grid = {\n",
        "    'iterations': [100, 200, 500, 1000],\n",
        "    'learning_rate': [0.03, 0.1],\n",
        "    'depth': [2, 4, 6, 8],\n",
        "    'l2_leaf_reg': [0.2, 0.5, 1, 3]\n",
        "}"
      ],
      "metadata": {
        "id": "NQXl_EY7s2tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=cb.CatBoostRegressor(random_seed=42, logging_level='Silent'), param_distributions=grid,\n",
        "    refit=True, verbose=3, cv=5, scoring='r2', n_jobs=-1, n_iter=50\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best R2 score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "-EFKPoir6GJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "train_metrics = compute_metrics(best_model, X_train, y_train)\n",
        "train_metrics"
      ],
      "metadata": {
        "id": "UzPi5Qq7YnQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics = compute_metrics(best_model, X_test, y_test)\n",
        "val_metrics"
      ],
      "metadata": {
        "id": "WNCwNfxqrGNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Residual plots"
      ],
      "metadata": {
        "id": "GfkgFH5wb1bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.contrib.wrapper import wrap"
      ],
      "metadata": {
        "id": "elKsLU6oaBwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer = residuals_plot(\n",
        "    wrap(best_model), X_train, y_train, X_test, y_test,\n",
        ")"
      ],
      "metadata": {
        "id": "3q6DA_eLYpSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer = residuals_plot(\n",
        "    wrap(best_model), X_train, y_train, X_test, y_test, hist=False, qqplot=True\n",
        ")"
      ],
      "metadata": {
        "id": "dYY1tX-6cKIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The QQ-Plot shows the residuals are normally distributed, because their quantiles when plotted against quantiles of normal distribution forms a straight line."
      ],
      "metadata": {
        "id": "FBUQqMsXeM9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Error"
      ],
      "metadata": {
        "id": "ylsAx5Dveh-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer = prediction_error(wrap(best_model), X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "NKOzKn0oeBCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance"
      ],
      "metadata": {
        "id": "ENLMAoMcBiPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = abs(best_model.feature_importances_)\n",
        "coef_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Variable\": df.drop(['price', 'log1p_price'], axis=1).columns,\n",
        "        \"Value\": variables,\n",
        "    }\n",
        ")\n",
        "n = 10\n",
        "sorted_df = (\n",
        "    coef_df.sort_values(by=\"Value\", ascending=False)\n",
        "    .head(n)\n",
        "    .sort_values(by=\"Value\")\n",
        ")\n",
        "sorted_df"
      ],
      "metadata": {
        "id": "Kgpl-kkvBKAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_range = range(1, len(sorted_df.index) + 1)\n",
        "plt.figure(figsize=(8, 5 * (n // 10)))\n",
        "plt.hlines(\n",
        "    y=my_range,\n",
        "    xmin=0,\n",
        "    xmax=sorted_df[\"Value\"],\n",
        "    color=\"skyblue\",\n",
        ")\n",
        "plt.plot(sorted_df[\"Value\"], my_range, \"o\")\n",
        "plt.yticks(my_range, sorted_df[\"Variable\"])\n",
        "plt.title(\"CatBoostRegressor Feature Importance Plot\")\n",
        "plt.xlabel(\"Variable Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HRzDQRp1Dzn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP Values"
      ],
      "metadata": {
        "id": "AS7go-nXbutn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(best_model)\n",
        "\n",
        "shap_values = explainer.shap_values(X_test)"
      ],
      "metadata": {
        "id": "MReJ7JbJbuEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names=coef_df.sort_values(by=\"Value\", ascending=False)['Variable'].values\n",
        "feature_names"
      ],
      "metadata": {
        "id": "NwvCyNNRcF3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_test, feature_names=feature_names)"
      ],
      "metadata": {
        "id": "e2rMPXicdOow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize decision tree"
      ],
      "metadata": {
        "id": "IUsIDT-Xg5YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.plot_tree(\n",
        "    tree_idx=0,\n",
        ")"
      ],
      "metadata": {
        "id": "RMoRAsFmg4jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actual Predictions"
      ],
      "metadata": {
        "id": "rAw3_K2ctfHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "PpcOmSN_tz5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse the log transformation\n",
        "actual_preds = np.expm1(preds)\n",
        "actual_y_test = np.expm1(y_test)\n",
        "\n",
        "# Compute metrics on the original scale\n",
        "def compute_metrics_original_scale(y_true, y_pred):\n",
        "    return pd.DataFrame([{\n",
        "        \"R2\": round(metrics.r2_score(y_true, y_pred), 3),\n",
        "        \"mse\": round(metrics.mean_squared_error(y_true, y_pred), 3),\n",
        "        \"rmse\": round(np.sqrt(metrics.mean_squared_error(y_true, y_pred)), 3),\n",
        "        \"mae\": round(metrics.mean_absolute_error(y_true, y_pred), 3),\n",
        "    }])\n",
        "\n",
        "val_metrics_original_scale = compute_metrics_original_scale(actual_y_test, actual_preds)\n",
        "val_metrics_original_scale"
      ],
      "metadata": {
        "id": "sacen5ETvmC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame({\"actual\": actual_y_test, \"pred\": actual_preds})\n",
        "pred_df.head(10)"
      ],
      "metadata": {
        "id": "n2CE1q0vuxTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pred_df.actual, pred_df.pred, c='crimson')\n",
        "p1 = max(max(pred_df.actual), max(pred_df.pred))\n",
        "p2 = min(min(pred_df.actual), min(pred_df.pred))\n",
        "plt.plot([p1, p2], [p1, p2], 'b-')\n",
        "plt.xlabel('Actual Values', fontsize=15)\n",
        "plt.ylabel('Predicted Values', fontsize=15)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y5BFO2rpvPN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot((pred_df.actual-pred_df.pred))\n",
        "plt.title('Distribution of residuals')\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RoGRQnUOvZsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Pipeline"
      ],
      "metadata": {
        "id": "1qK3xObewy-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/house_rentals_cleaned.csv')"
      ],
      "metadata": {
        "id": "RK3zkFHwvhGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "F8Z8PYubw5IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['amenities'].head()"
      ],
      "metadata": {
        "id": "aJ7nU3wq6TkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_cols = [\"category\", \"condition\", \"furnishing\"]\n",
        "text_cols = [\"amenities\"]\n",
        "bool_cols = ['parking_space']\n",
        "target_columns = ['log1p_price']\n",
        "numeric_cols = list(set(df.columns) - set(target_columns) - set(category_cols) - set(text_cols) - set(bool_cols))"
      ],
      "metadata": {
        "id": "Anz4xM_6xCuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import FunctionTransformer\n"
      ],
      "metadata": {
        "id": "15DcXihNxVPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_preprocessor = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputation_mean\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "categorical_preprocessor = Pipeline(\n",
        "    steps=[\n",
        "        (\n",
        "            \"imputation_most_frequent\",\n",
        "            SimpleImputer(strategy=\"most_frequent\"),\n",
        "        ),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def text_tokenizer(x):\n",
        "    return x.split(',')\n",
        "\n",
        "text_preprocessor = Pipeline(\n",
        "    steps=[\n",
        "        (\"count_vectorizer\", CountVectorizer(max_features=20,tokenizer=text_tokenizer, binary=True))\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"numeric\", numeric_preprocessor, numeric_cols),\n",
        "        (\"categorical\", categorical_preprocessor, category_cols),\n",
        "        (\"text\", text_preprocessor, text_cols[0]),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "3V_PRL6bxFaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {'learning_rate': 0.03, 'l2_leaf_reg': 1, 'iterations': 1000, 'depth': 8}\n",
        "\n",
        "pipe = make_pipeline(preprocessor, cb.CatBoostRegressor(random_seed=42, logging_level='Silent', **best_params))\n",
        "pipe"
      ],
      "metadata": {
        "id": "ssvzIN0zxTnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for model evaluation\n",
        "X = df.drop(columns=['log1p_price'], axis=1)\n",
        "y = df['log1p_price'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, y, train_size=0.8, shuffle=True, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "gwqjAVpIzE1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "a64vJKMb0NPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline to your training data\n",
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "R8Ys265_z2-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "2sO6txaF2ik1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "h64fmolI2cQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the pipeline to disk\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Assuming 'pipe' is your fitted pipeline\n",
        "joblib.dump(pipe, 'house_rental_pipeline.joblib')"
      ],
      "metadata": {
        "id": "2oItNup46wog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha house_rental_pipeline.joblib"
      ],
      "metadata": {
        "id": "wkD_lMaG82j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp house_rental_pipeline.joblib /content/drive/MyDrive/Models/"
      ],
      "metadata": {
        "id": "3rZ5jFRj9xhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = joblib.load('house_rental_pipeline.joblib')\n",
        "pipe"
      ],
      "metadata": {
        "id": "O1bDv_Ez9-nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in category_cols:\n",
        "    print(col, df[col].unique())"
      ],
      "metadata": {
        "id": "0ggDEY4l-Opz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a counter to count amentities in the dataset\n",
        "results = Counter()\n",
        "df.amenities.apply(lambda x: results.update(x.split(\",\")))\n",
        "# create a new sub dataframe with 'amenity' and 'count'\n",
        "amenity_df = pd.DataFrame(results.most_common(), columns=['amenity', 'count'])\n",
        "amenity_df"
      ],
      "metadata": {
        "id": "6eLzd4Um-ZF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amenity_df['amenity'].values.tolist()"
      ],
      "metadata": {
        "id": "CZas5K1J_PSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-rLV-i8_3__"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}